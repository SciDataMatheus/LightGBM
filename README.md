# Case de Predi√ß√£o de Fraudes em Transa√ß√µes de Cart√£o de Cr√©dito üí≥

## Contexto:

Me coloco no lugar de um cientista de dados em uma institui√ß√£o financeira renomada. A empresa est√° enfrentando um aumento significativo nas transa√ß√µes fraudulentas de cart√µes de cr√©dito, o que est√° prejudicando a confian√ßa dos clientes e causando preju√≠zos financeiros. Sua tarefa √© desenvolver um modelo preditivo que possa identificar transa√ß√µes fraudulentas com alta precis√£o, minimizando assim o impacto financeiro e protegendo a reputa√ß√£o da institui√ß√£o.

## Base de Dados:

"**fraud_dataset.csv**", que cont√©m informa√ß√µes detalhadas sobre as transa√ß√µes de cart√µes de cr√©dito. 

## Objetivo:

Desenvolver um modelo preditivo utilizando o algoritmo de Regress√£o Log√≠stica com regulariza√ß√£o L2 para prever se uma transa√ß√£o de cart√£o de cr√©dito √© fraudulenta ou n√£o.

**Realize os seguintes passos na sua entrega:**

- Pr√©-processamento de Dados:
  - Verifique se a base de dados cont√©m informa√ß√µes nulas.
  - Considere a padroniza√ß√£o de vari√°veis num√©ricas.
- Divis√£o da Base de Dados:
  - Separe a base de dados utilizando a t√©cnica hold out, mantendo uma propor√ß√£o adequada para garantir a representatividade dos dados.
  - Caso a base de dados tenha algum tipo de desequil√≠brio, aplique uma t√©cnica de oversampling para equilibrar as classes.
- Modelagem:
  - Implemente o algoritmo de Regress√£o Log√≠stica com regulariza√ß√£o L2.
  - Utilize a t√©cnica de valida√ß√£o cruzada k-fold (com 5 folds) para avaliar o desempenho do modelo.
- Avalia√ß√£o do Modelo:
  - Avalie o modelo utilizando m√©tricas como precis√£o, recall, F1-score e √°rea sob a curva ROC (AUC-ROC).
- Interpreta√ß√£o e Comunica√ß√£o de Resultados:
  - Comunique os resultados de forma clara e acess√≠vel para as partes interessadas, destacando a efic√°cia do modelo na identifica√ß√£o de transa√ß√µes fraudulentas.

# Al√©m do objetivo proposto

Pretendo implementar uma classifica√ß√£o usando LightGBM e comparar o resultados

# LightGBM

Boosting √© uma t√©cnica de ensemble que cria um modelo preditivo forte a partir de uma combina√ß√£o de v√°rios modelos fracos. Ao contr√°rio do Bagging, onde os modelos s√£o treinados de forma independente, o Boosting treina modelos de forma sequencial. Cada novo modelo tenta corrigir os erros cometidos pelos modelos anteriores, resultando em um modelo final mais preciso e robusto.

## Como o Boosting Funciona:

1. Modelo Inicial:

  - O processo come√ßa com a cria√ß√£o de um modelo fraco (geralmente uma √°rvore de decis√£o simples). Um modelo fraco √© um modelo que, por si s√≥, tem desempenho ligeiramente melhor que uma escolha aleat√≥ria.
2. Pesos e Erros:

  - Ap√≥s o primeiro modelo ser treinado, o Boosting atribui pesos maiores √†s observa√ß√µes que foram incorretamente classificadas ou previstas. Isso significa que as observa√ß√µes que foram dif√≠ceis de prever ter√£o mais import√¢ncia na pr√≥xima rodada de treinamento.

3. Modelo Sequencial:

  - Um novo modelo √© treinado com base nos dados ajustados (ou seja, com os pesos atualizados). Esse novo modelo tenta corrigir os erros do modelo anterior, focando mais nos casos onde o primeiro modelo falhou.

4. Combina√ß√£o de Modelos:

  - O processo continua de forma iterativa, adicionando novos modelos que tentam corrigir os erros de seus predecessores.
    O modelo final √© obtido atrav√©s da combina√ß√£o ponderada dos modelos fracos, onde os modelos que t√™m melhor desempenho recebem maior peso na predi√ß√£o final.
    
5. Resultado Final:

  - O modelo final √© uma "soma ponderada" de todos os modelos fracos, resultando em um modelo preditivo forte que geralmente tem alta precis√£o.

### Como funciona o Gradient Boosting:

  - Esta t√©cnica ajusta modelos sequenciais para minimizar o erro residual do modelo anterior, utilizando t√©cnicas de otimiza√ß√£o de gradiente.

## Como funciona o Light GBM:

  - √â uma implementa√ß√£o otimizada do algoritmo de boosting, projetada para ser mais eficiente, r√°pida e escal√°vel do que outras abordagens de gradient boosting, como o GBM tradicional.
  - LightGBM usa um conceito de boosting semelhante ao GBM, onde v√°rias √°rvores de decis√£o s√£o ajustadas sequencialmente, com cada nova √°rvore corrigindo os erros das √°rvores anteriores. O objetivo √© minimizar uma fun√ß√£o de perda atrav√©s de itera√ß√µes.
 

